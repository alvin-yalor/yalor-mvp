# Yalor MVP: ACE (AI Commerce Exchange) Architecture

This Next.js application implements the Phase 1 (MVP) architecture for the **AI Commerce Exchange (ACE)**. It features an event-driven "Majestic Monolith" design using an internal Node.js `EventEmitter` to handle the asynchronous, multi-actor flow with incredibly low latency.

## Architecture Overview

We have adopted an Event-Driven Architecture (EDA) to seamlessly bridge standard AdTech (OpenRTB) and Conversational AI platforms. 

### 1. ACE Core Pipeline (The Brain)
- **Profiler**: Tracks session state and calculates scores to filter out low-intent users before querying partners.
- **Intent Analyzer**: "Reads" natural language messages from the AI chat, extracts context (e.g., "I need BBQ steaks"), and emits `OPPORTUNITY_IDENTIFIED`.
- **Bid Assessor**: Waits for OpenRTB-compliant bids over a predefined time window (`250ms`) and computes the highest-yield winner.

### 2. ACE Media Network (The Integrator)
- **Event Router**: Subscribes to new opportunities and fans out requests to configured DSPs (Demand Side Platforms).
- **Dummy Coupon DSP**: Simulates external media partner bidding by formatting opportunities into standard JSON payloads and querying external integrations.

### 3. ACE Message Control Protocol (MCP)
- Implemented as a Next.js API Route (`/api/mcp`) running as the ingress point.
- Translates synchronous HTTP POST requests from AI Platforms into asynchronous Event Bus triggers.
- Waits for the auction result and serializes the output into the **AdCP + ARTF** (AI Response Tracking Framework) standard schema for client egress.

## Quick Start
First, install the dependencies if you haven't already, then run the development server:

```bash
npm run dev
# or yarn dev, pnpm dev, bun dev
```

Open [http://localhost:3000](http://localhost:3000) with your browser.

## Testing the Flow
The application features a beautifully animated, Vercel AI SDK-style Generative UI. The conversational interface natively merges standard text responses with the `AdCP` interactive payloads generated by the ACE Engine.

To test the end-to-end integration:
1. Open [http://localhost:3000](http://localhost:3000)
2. Type `"I need to buy some steaks for a BBQ tonight."` into the chat box.
3. Observe the chat stream.
   - The React orchestrator concurrently queries the LLM (`/api/chat`) and the ACE MCP (`/api/mcp`).
   - The LLM streams back a natural response with smooth layout animations.
   - Simultaneously, the ACE Engine instantly runs the auction (~410ms round-trip) and injects an interactive Sponsored Card (e.g., a Wagyu Steak coupon) directly into the stream!
4. **Automated ARTF Tracking**: When you scroll down and the card comes into view, an `on_ad_rendered` webhook is silently fired back to the ACE server to guarantee viewability monetization.

## Roadmap: Phase 2 (Scale)
When volume requires separate scaling, the architecture is designed to cleanly transition to:
- **Logical to Physical Microservices**: Splitting Client, ACE Core, and the Media Network.
- **Event Bus Migration**: Migrating from an in-memory `EventEmitter` to Redis Pub/Sub, AWS EventBridge, or SQS.
- **Model Inference**: Shifting from managed LLMs via APIs to self-hosted Small Language Models (SLMs).
